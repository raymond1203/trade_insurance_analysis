{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 01 ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬\n",
    "\n",
    "## ëª©í‘œ\n",
    "- ì›ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° íƒìƒ‰\n",
    "- ê²°ì¸¡ì¹˜/ì´ìƒì¹˜ ì²˜ë¦¬\n",
    "- ë°ì´í„° í†µí•© ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "- ë¶„ì„ìš© ë°ì´í„°ì…‹ ì €ì¥\n",
    "\n",
    "## ë°ì´í„° íŒŒì¼\n",
    "1. **ìˆ˜ì¶œì…ì‹¤ì  (2021-2023)**: ì›”ë³„_í’ˆëª©ë³„_êµ­ê°€ë³„ ìˆ˜ì¶œì…ì‹¤ì \n",
    "2. **ë³´ìƒí˜„í™© (2024)**: í•œêµ­ë¬´ì—­ë³´í—˜ê³µì‚¬_êµ­ê°€ë³„ ë‹¨ê¸°ìˆ˜ì¶œë³´í—˜ ë³´ìƒí˜„í™©\n",
    "3. **ìœ„í—˜ì§€ìˆ˜ (2025)**: í•œêµ­ë¬´ì—­ë³´í—˜ê³µì‚¬_êµ­ê°€ë³„ ì—…ì¢…ë³„ ìœ„í—˜ì§€ìˆ˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°ì´í„° íŒŒì¼ ëª©ë¡:\n",
      "  - ì›”ë³„ í’ˆëª©ë³„ êµ­ê°€ë³„ ìˆ˜ì¶œì…ì‹¤ì (2023ë…„).csv\n",
      "  - ì›”ë³„_í’ˆëª©ë³„_êµ­ê°€ë³„ ìˆ˜ì¶œì…ì‹¤ì (2021ë…„).csv\n",
      "  - ì›”ë³„_í’ˆëª©ë³„_êµ­ê°€ë³„ ìˆ˜ì¶œì…ì‹¤ì (2022ë…„).csv\n",
      "  - í•œêµ­ë¬´ì—­ë³´í—˜ê³µì‚¬_êµ­ê°€ë³„ ë‹¨ê¸°ìˆ˜ì¶œë³´í—˜ ë³´ìƒí˜„í™©_20240630.csv\n",
      "  - í•œêµ­ë¬´ì—­ë³´í—˜ê³µì‚¬_êµ­ê°€ë³„ ì—…ì¢…ë³„ ìœ„í—˜ì§€ìˆ˜(RISK INDEX)_20250501.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "DATA_PATH = Path('../data')\n",
    "\n",
    "print(\"ğŸ“‚ ë°ì´í„° íŒŒì¼ ëª©ë¡:\")\n",
    "for file in DATA_PATH.glob('*.csv'):\n",
    "    print(f\"  - {file.name}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. ìˆ˜ì¶œì…ì‹¤ì  ë°ì´í„° ë¡œë”© (2021-2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 2021ë…„ ìˆ˜ì¶œì…ì‹¤ì  ë¡œë”© ì„±ê³µ (ì¸ì½”ë”©: cp949)\n",
      "âœ… 2022ë…„ ìˆ˜ì¶œì…ì‹¤ì  ë¡œë”© ì„±ê³µ (ì¸ì½”ë”©: utf-8)\n",
      "âœ… 2023ë…„ ìˆ˜ì¶œì…ì‹¤ì  ë¡œë”© ì„±ê³µ (ì¸ì½”ë”©: cp949)\n",
      "2021ë…„: (511253, 8)\n",
      "2022ë…„: (504923, 8)\n",
      "2023ë…„: (500978, 8)\n",
      "\n",
      "ğŸ“ˆ í†µí•© ìˆ˜ì¶œì… ë°ì´í„°: (1517154, 8)\n",
      "\n",
      "ğŸ“Š ë°ì´í„° ìƒ˜í”Œ:\n",
      "        ì›”ë³„  ì„¸ë²ˆ4ë‹¨ìœ„    êµ­ê°€  ìˆ˜ì¶œì¤‘ëŸ‰  ìˆ˜ì…ì¤‘ëŸ‰  ìˆ˜ì¶œì•¡  ìˆ˜ì…ì•¡    ì—°ë„\n",
      "0  2021-03    101  ë„¤ëœë€ë“œ     0     2    0  130  2021\n",
      "1  2021-05    101  ë„¤ëœë€ë“œ     0     2    0  141  2021\n",
      "2  2021-06    101  ë„¤ëœë€ë“œ     0     1    0  162  2021\n",
      "3  2021-07    101  ë„¤ëœë€ë“œ     0     2    0  150  2021\n",
      "4  2021-08    101  ë„¤ëœë€ë“œ     0     1    0   70  2021\n",
      "\n",
      "ì»¬ëŸ¼: ['ì›”ë³„', 'ì„¸ë²ˆ4ë‹¨ìœ„', 'êµ­ê°€', 'ìˆ˜ì¶œì¤‘ëŸ‰', 'ìˆ˜ì…ì¤‘ëŸ‰', 'ìˆ˜ì¶œì•¡', 'ìˆ˜ì…ì•¡', 'ì—°ë„']\n"
     ]
    }
   ],
   "source": [
    "# ìˆ˜ì¶œì…ì‹¤ì  ë°ì´í„° ë¡œë”© (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)\n",
    "def load_csv_with_encoding(file_path, file_name):\n",
    "    \"\"\"ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ CSV íŒŒì¼ ë¡œë”© ì‹œë„\"\"\"\n",
    "    encodings = ['cp949', 'euc-kr', 'utf-8', 'utf-8-sig', 'latin1']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=encoding)\n",
    "            print(f\"âœ… {file_name} ë¡œë”© ì„±ê³µ (ì¸ì½”ë”©: {encoding})\")\n",
    "            return df\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {file_name} ë¡œë”© ì‹¤íŒ¨ ({encoding}): {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"âŒ {file_name} ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨\")\n",
    "    return None\n",
    "\n",
    "# ìˆ˜ì¶œì…ì‹¤ì  íŒŒì¼ë“¤ ë¡œë”©\n",
    "df_export_2021 = load_csv_with_encoding(DATA_PATH / 'ì›”ë³„_í’ˆëª©ë³„_êµ­ê°€ë³„ ìˆ˜ì¶œì…ì‹¤ì (2021ë…„).csv', '2021ë…„ ìˆ˜ì¶œì…ì‹¤ì ')\n",
    "df_export_2022 = load_csv_with_encoding(DATA_PATH / 'ì›”ë³„_í’ˆëª©ë³„_êµ­ê°€ë³„ ìˆ˜ì¶œì…ì‹¤ì (2022ë…„).csv', '2022ë…„ ìˆ˜ì¶œì…ì‹¤ì ')\n",
    "df_export_2023 = load_csv_with_encoding(DATA_PATH / 'ì›”ë³„ í’ˆëª©ë³„ êµ­ê°€ë³„ ìˆ˜ì¶œì…ì‹¤ì (2023ë…„).csv', '2023ë…„ ìˆ˜ì¶œì…ì‹¤ì ')\n",
    "\n",
    "# ë°ì´í„° ë¡œë”© ì„±ê³µ ì—¬ë¶€ í™•ì¸\n",
    "loaded_dfs = []\n",
    "if df_export_2021 is not None:\n",
    "    df_export_2021['ì—°ë„'] = 2021\n",
    "    loaded_dfs.append(df_export_2021)\n",
    "    print(f\"2021ë…„: {df_export_2021.shape}\")\n",
    "\n",
    "if df_export_2022 is not None:\n",
    "    df_export_2022['ì—°ë„'] = 2022\n",
    "    loaded_dfs.append(df_export_2022)\n",
    "    print(f\"2022ë…„: {df_export_2022.shape}\")\n",
    "\n",
    "if df_export_2023 is not None:\n",
    "    df_export_2023['ì—°ë„'] = 2023\n",
    "    loaded_dfs.append(df_export_2023)\n",
    "    print(f\"2023ë…„: {df_export_2023.shape}\")\n",
    "\n",
    "# ë¡œë”©ëœ ë°ì´í„°ë“¤ í†µí•©\n",
    "if loaded_dfs:\n",
    "    df_export_all = pd.concat(loaded_dfs, ignore_index=True)\n",
    "    print(f\"\\nğŸ“ˆ í†µí•© ìˆ˜ì¶œì… ë°ì´í„°: {df_export_all.shape}\")\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ ë¡œë”©ëœ ë°ì´í„°ì˜ êµ¬ì¡° í™•ì¸\n",
    "    print(\"\\nğŸ“Š ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "    print(loaded_dfs[0].head())\n",
    "    print(f\"\\nì»¬ëŸ¼: {loaded_dfs[0].columns.tolist()}\")\n",
    "else:\n",
    "    print(\"âŒ ìˆ˜ì¶œì… ë°ì´í„°ë¥¼ í•˜ë‚˜ë„ ë¡œë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. ë³´ìƒí˜„í™© ë°ì´í„° ë¡œë”© (2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³´ìƒí˜„í™© ë°ì´í„° ë¡œë”© ì„±ê³µ (ì¸ì½”ë”©: cp949)\n",
      "Shape: (1235, 4)\n",
      "\n",
      "ğŸ“Š ë³´ìƒí˜„í™© ë°ì´í„° ìƒ˜í”Œ:\n",
      "          êµ¬ë¶„   êµ­ê°€ëª…         ë³´í—˜ê¸ˆ         íšŒìˆ˜ê¸ˆ\n",
      "0  2021ë…„ ìƒë°˜ê¸°  ëŒ€í•œë¯¼êµ­           0           0\n",
      "1  2021ë…„ ìƒë°˜ê¸°    ëŒ€ë§Œ     3055140    36574531\n",
      "2  2021ë…„ ìƒë°˜ê¸°    ì¤‘êµ­  1461543917  1791600907\n",
      "3  2021ë…„ ìƒë°˜ê¸°    í™ì½©   293886636     5853681\n",
      "4  2021ë…„ ìƒë°˜ê¸°    ì¼ë³¸    54277920    47212682\n",
      "\n",
      "ì»¬ëŸ¼: ['êµ¬ë¶„', 'êµ­ê°€ëª…', 'ë³´í—˜ê¸ˆ', 'íšŒìˆ˜ê¸ˆ']\n",
      "\n",
      "ğŸ”§ ì»¬ëŸ¼ëª… ì •ë¦¬ ì™„ë£Œ: ['ë…„ë¶„ê¸°', 'êµ­ê°€ëª…', 'ë³´ìƒê¸ˆ', 'íšŒìˆ˜ê¸ˆ']\n",
      "ğŸ“… ì—°ë„ë¶„ê¸° ë¶„ë¦¬ ì™„ë£Œ:\n",
      "- ì—°ë„ ë²”ìœ„: 2021-2024\n",
      "- ë¶„ê¸° ë¶„í¬: {2: 1235}\n",
      "ğŸ’° ìˆ«ìí˜• ë³€í™˜ ì™„ë£Œ:\n",
      "- ì´ ë³´ìƒê¸ˆ: 272,167,353,323ì›\n",
      "- ì´ íšŒìˆ˜ê¸ˆ: 170,206,556,495ì›\n",
      "- í‰ê·  ë³´ìƒë¥ : 0.2190\n",
      "\n",
      "ğŸ“ˆ ì£¼ìš” í†µê³„:\n",
      "                ë³´ìƒê¸ˆ           íšŒìˆ˜ê¸ˆ          ë³´ìƒë¥ \n",
      "count  1.235000e+03  1.235000e+03  1235.000000\n",
      "mean   2.203784e+08  1.378191e+08     0.218960\n",
      "std    1.035501e+09  1.188133e+09     0.374047\n",
      "min    0.000000e+00 -2.194602e+07     0.000000\n",
      "25%    0.000000e+00  0.000000e+00     0.000000\n",
      "50%    0.000000e+00  0.000000e+00     0.000000\n",
      "75%    3.270208e+07  1.271672e+07     0.366200\n",
      "max    1.772370e+10  3.716997e+10     1.000000\n"
     ]
    }
   ],
   "source": [
    "# ë³´ìƒí˜„í™© ë°ì´í„° ë¡œë”© (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)\n",
    "df_claims_2024 = load_csv_with_encoding(\n",
    "    DATA_PATH / 'í•œêµ­ë¬´ì—­ë³´í—˜ê³µì‚¬_êµ­ê°€ë³„ ë‹¨ê¸°ìˆ˜ì¶œë³´í—˜ ë³´ìƒí˜„í™©_20240630.csv', \n",
    "    'ë³´ìƒí˜„í™© ë°ì´í„°'\n",
    ")\n",
    "\n",
    "if df_claims_2024 is not None:\n",
    "    print(f\"Shape: {df_claims_2024.shape}\")\n",
    "    \n",
    "    # ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
    "    print(\"\\nğŸ“Š ë³´ìƒí˜„í™© ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "    print(df_claims_2024.head())\n",
    "    print(f\"\\nì»¬ëŸ¼: {df_claims_2024.columns.tolist()}\")\n",
    "    \n",
    "    # ë³´ìƒí˜„í™© ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    df_claims_2024.columns = ['ë…„ë¶„ê¸°', 'êµ­ê°€ëª…', 'ë³´ìƒê¸ˆ', 'íšŒìˆ˜ê¸ˆ']\n",
    "    print(f\"\\nğŸ”§ ì»¬ëŸ¼ëª… ì •ë¦¬ ì™„ë£Œ: {df_claims_2024.columns.tolist()}\")\n",
    "    \n",
    "    # ì—°ë„ë¶„ê¸° ë¶„ë¦¬ (NaN ê°’ ì²˜ë¦¬)\n",
    "    # ì—°ë„ ì¶”ì¶œ\n",
    "    df_claims_2024['ì—°ë„'] = df_claims_2024['ë…„ë¶„ê¸°'].str.extract('(\\d{4})')\n",
    "    df_claims_2024['ì—°ë„'] = pd.to_numeric(df_claims_2024['ì—°ë„'], errors='coerce').fillna(2024).astype(int)\n",
    "    \n",
    "    # ë¶„ê¸° ì¶”ì¶œ (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)\n",
    "    # íŒ¨í„´ 1: \"Xë¶„ê¸°\" í˜•íƒœ\n",
    "    ë¶„ê¸°1 = df_claims_2024['ë…„ë¶„ê¸°'].str.extract('(\\d)ë¶„ê¸°')\n",
    "    # íŒ¨í„´ 2: \"ìƒë°˜ê¸°\", \"í•˜ë°˜ê¸°\" í˜•íƒœ\n",
    "    ë¶„ê¸°2 = df_claims_2024['ë…„ë¶„ê¸°'].str.replace('ìƒë°˜ê¸°', '1').str.replace('í•˜ë°˜ê¸°', '2')\n",
    "    ë¶„ê¸°2 = pd.to_numeric(ë¶„ê¸°2.str.extract('(\\d)')[0], errors='coerce')\n",
    "    \n",
    "    # ë‘ íŒ¨í„´ ê²°í•©\n",
    "    df_claims_2024['ë¶„ê¸°'] = pd.to_numeric(ë¶„ê¸°1[0], errors='coerce').fillna(ë¶„ê¸°2).fillna(1).astype(int)\n",
    "    \n",
    "    print(f\"ğŸ“… ì—°ë„ë¶„ê¸° ë¶„ë¦¬ ì™„ë£Œ:\")\n",
    "    print(f\"- ì—°ë„ ë²”ìœ„: {df_claims_2024['ì—°ë„'].min()}-{df_claims_2024['ì—°ë„'].max()}\")\n",
    "    print(f\"- ë¶„ê¸° ë¶„í¬: {df_claims_2024['ë¶„ê¸°'].value_counts().sort_index().to_dict()}\")\n",
    "    \n",
    "    # ìˆ«ìí˜• ë³€í™˜ (ì½¤ë§ˆ, ê³µë°±, ê¸°íƒ€ ë¬¸ì ì œê±°)\n",
    "    numeric_cols = ['ë³´ìƒê¸ˆ', 'íšŒìˆ˜ê¸ˆ']\n",
    "    for col in numeric_cols:\n",
    "        if df_claims_2024[col].dtype == 'object':\n",
    "            # ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ì ì œê±°\n",
    "            df_claims_2024[col] = df_claims_2024[col].astype(str).str.replace(',', '').str.replace(' ', '').str.replace('ì›', '')\n",
    "            # ìˆ«ìë§Œ ì¶”ì¶œ\n",
    "            df_claims_2024[col] = df_claims_2024[col].str.extract('(\\d+)')[0]\n",
    "            df_claims_2024[col] = pd.to_numeric(df_claims_2024[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€í•œ ë¹„ìœ¨ ê³„ì‚°\n",
    "    total_amount = df_claims_2024['ë³´ìƒê¸ˆ'] + df_claims_2024['íšŒìˆ˜ê¸ˆ']\n",
    "    df_claims_2024['ë³´ìƒë¥ '] = np.where(total_amount > 0, \n",
    "                                     df_claims_2024['ë³´ìƒê¸ˆ'] / total_amount, 0)\n",
    "    \n",
    "    total_claims = df_claims_2024['ë³´ìƒê¸ˆ'].sum()\n",
    "    df_claims_2024['ì†ì‹¤ë¥ '] = np.where(total_claims > 0,\n",
    "                                     df_claims_2024['ë³´ìƒê¸ˆ'] / total_claims, 0)\n",
    "    \n",
    "    print(f\"ğŸ’° ìˆ«ìí˜• ë³€í™˜ ì™„ë£Œ:\")\n",
    "    print(f\"- ì´ ë³´ìƒê¸ˆ: {df_claims_2024['ë³´ìƒê¸ˆ'].sum():,.0f}ì›\")\n",
    "    print(f\"- ì´ íšŒìˆ˜ê¸ˆ: {df_claims_2024['íšŒìˆ˜ê¸ˆ'].sum():,.0f}ì›\")\n",
    "    print(f\"- í‰ê·  ë³´ìƒë¥ : {df_claims_2024['ë³´ìƒë¥ '].mean():.4f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ ì£¼ìš” í†µê³„:\")\n",
    "    print(df_claims_2024[['ë³´ìƒê¸ˆ', 'íšŒìˆ˜ê¸ˆ', 'ë³´ìƒë¥ ']].describe())\n",
    "else:\n",
    "    print(\"âŒ ë³´ìƒí˜„í™© ë°ì´í„°ë¥¼ ë¡œë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. AI ìœ„í—˜ì§€ìˆ˜ ë°ì´í„° ë¡œë”© (2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AI ìœ„í—˜ì§€ìˆ˜ ë°ì´í„° ë¡œë”© ì„±ê³µ (ì¸ì½”ë”©: cp949)\n",
      "Shape: (24584, 4)\n",
      "\n",
      "ğŸ“Š AI ìœ„í—˜ì§€ìˆ˜ ë°ì´í„° ìƒ˜í”Œ:\n",
      "      ê¸°ì¤€ë…„ì›” êµ­ê°€í•œê¸€ëª…                    ì—…ì¢…í•œê¸€ëª…  ìœ„í—˜ì§€ìˆ˜(Risk Index)\n",
      "0  2025-04    ê°€ë‚˜          ê³ ë¬´ ë° í”Œë¼ìŠ¤í‹±ì œí’ˆ ì œì¡°ì—…                 5\n",
      "1  2025-04    ê°€ë‚˜                    ê¸ˆì† ê´‘ì—…                 5\n",
      "2  2025-04    ê°€ë‚˜              ë„ë§¤ ë° ìƒí’ˆ ì¤‘ê°œì—…                 4\n",
      "3  2025-04    ê°€ë‚˜           ìë™ì°¨ ë° íŠ¸ë ˆì¼ëŸ¬ ì œì¡°ì—…                 4\n",
      "4  2025-04    ê°€ë‚˜  í™”í•™ë¬¼ì§ˆ ë° í™”í•™ì œí’ˆ ì œì¡°ì—…; ì˜ì•½í’ˆ ì œì™¸                 5\n",
      "\n",
      "ì»¬ëŸ¼: ['ê¸°ì¤€ë…„ì›”', 'êµ­ê°€í•œê¸€ëª…', 'ì—…ì¢…í•œê¸€ëª…', 'ìœ„í—˜ì§€ìˆ˜(Risk Index)']\n",
      "\n",
      "ğŸ”§ ì»¬ëŸ¼ëª… ì •ë¦¬ ì™„ë£Œ: ['ê¸°ì¤€ë…„ì›”', 'êµ­ê°€ëª…', 'ì—…ì¢…ëª…', 'ìœ„í—˜ì§€ìˆ˜']\n",
      "\n",
      "ğŸ“Š ìœ„í—˜ì§€ìˆ˜ ë¶„í¬:\n",
      "ìœ„í—˜ì§€ìˆ˜\n",
      "1    2943\n",
      "2    6727\n",
      "3    5126\n",
      "4    7352\n",
      "5    2436\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸŒ êµ­ê°€ë³„ í‰ê·  ìœ„í—˜ì§€ìˆ˜ (ìƒìœ„ 10ê°œêµ­):\n",
      "         mean  std  count\n",
      "êµ­ê°€ëª…                      \n",
      "ì¹´ë©”ë£¬       5.0  0.0      8\n",
      "ì‹œì—ë¼ë¦¬ì˜¨     5.0  0.0      8\n",
      "íƒ€ì§€í‚¤ìŠ¤íƒ„     5.0  0.0     16\n",
      "ë¶€ë£¬ë””       5.0  0.0      8\n",
      "ë¶€ë¥´í‚¤ë‚˜íŒŒì†Œ    5.0  0.0     32\n",
      "ë¦¬ë¹„ì•„       5.0  0.0      8\n",
      "ë§ˆë‹¤ê°€ìŠ¤ì¹´ë¥´    5.0  0.0      4\n",
      "ë¼ì´ë² ë¦¬ì•„     5.0  0.0     13\n",
      "í‚¤ë¥´ê¸°ì¦ˆê³µí™”êµ­   5.0  0.0     16\n",
      "ë§ë¦¬        5.0  0.0     24\n"
     ]
    }
   ],
   "source": [
    "# AI ìœ„í—˜ì§€ìˆ˜ ë°ì´í„° ë¡œë”© (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)\n",
    "df_risk_2025 = load_csv_with_encoding(\n",
    "    DATA_PATH / 'í•œêµ­ë¬´ì—­ë³´í—˜ê³µì‚¬_êµ­ê°€ë³„ ì—…ì¢…ë³„ ìœ„í—˜ì§€ìˆ˜(RISK INDEX)_20250501.csv', \n",
    "    'AI ìœ„í—˜ì§€ìˆ˜ ë°ì´í„°'\n",
    ")\n",
    "\n",
    "if df_risk_2025 is not None:\n",
    "    print(f\"Shape: {df_risk_2025.shape}\")\n",
    "    \n",
    "    # ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
    "    print(\"\\nğŸ“Š AI ìœ„í—˜ì§€ìˆ˜ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "    print(df_risk_2025.head())\n",
    "    print(f\"\\nì»¬ëŸ¼: {df_risk_2025.columns.tolist()}\")\n",
    "    \n",
    "    # AI ìœ„í—˜ì§€ìˆ˜ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    df_risk_2025.columns = ['ê¸°ì¤€ë…„ì›”', 'êµ­ê°€ëª…', 'ì—…ì¢…ëª…', 'ìœ„í—˜ì§€ìˆ˜']\n",
    "    print(f\"\\nğŸ”§ ì»¬ëŸ¼ëª… ì •ë¦¬ ì™„ë£Œ: {df_risk_2025.columns.tolist()}\")\n",
    "    \n",
    "    # ìœ„í—˜ì§€ìˆ˜ê°€ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° ë³€í™˜\n",
    "    if df_risk_2025['ìœ„í—˜ì§€ìˆ˜'].dtype == 'object':\n",
    "        df_risk_2025['ìœ„í—˜ì§€ìˆ˜'] = pd.to_numeric(df_risk_2025['ìœ„í—˜ì§€ìˆ˜'], errors='coerce')\n",
    "    \n",
    "    # ìœ„í—˜ì§€ìˆ˜ ë¶„í¬ í™•ì¸\n",
    "    print(\"\\nğŸ“Š ìœ„í—˜ì§€ìˆ˜ ë¶„í¬:\")\n",
    "    print(df_risk_2025['ìœ„í—˜ì§€ìˆ˜'].value_counts().sort_index())\n",
    "    \n",
    "    # êµ­ê°€ë³„ í‰ê·  ìœ„í—˜ì§€ìˆ˜\n",
    "    country_risk = df_risk_2025.groupby('êµ­ê°€ëª…')['ìœ„í—˜ì§€ìˆ˜'].agg(['mean', 'std', 'count']).round(2)\n",
    "    print(f\"\\nğŸŒ êµ­ê°€ë³„ í‰ê·  ìœ„í—˜ì§€ìˆ˜ (ìƒìœ„ 10ê°œêµ­):\")\n",
    "    print(country_risk.sort_values('mean', ascending=False).head(10))\n",
    "else:\n",
    "    print(\"âŒ AI ìœ„í—˜ì§€ìˆ˜ ë°ì´í„°ë¥¼ ë¡œë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. ë°ì´í„° ì „ì²˜ë¦¬ ë° í†µí•©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… ì›”ë³„ ë°ì´í„° ìƒ˜í”Œ: ['2021-01', '2021-01', '2021-01', '2021-01', '2021-01']\n",
      "âœ… ë‚ ì§œ ë³€í™˜ ì™„ë£Œ: [Timestamp('2021-01-01 00:00:00'), Timestamp('2021-01-01 00:00:00'), Timestamp('2021-01-01 00:00:00'), Timestamp('2021-01-01 00:00:00'), Timestamp('2021-01-01 00:00:00')]\n",
      "âœ… ìˆ˜ì¶œ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: (8316, 6)\n",
      "ğŸ“Š ì§‘ê³„ëœ ìˆ˜ì¶œ ë°ì´í„° ìƒ˜í”Œ:\n",
      "     ì—°ë„       ì›”ë³„    êµ­ê°€    ìˆ˜ì¶œì•¡   ìˆ˜ì¶œì¤‘ëŸ‰         ë…„ì›”\n",
      "0  2021  2021-01    ê°€ë‚˜  21423  10066 2021-01-01\n",
      "1  2021  2021-01    ê°€ë´‰    944    153 2021-01-01\n",
      "2  2021  2021-01  ê°€ì´ì•„ë‚˜   2072    485 2021-01-01\n",
      "3  2021  2021-01   ê°ë¹„ì•„    351     70 2021-01-01\n",
      "4  2021  2021-01    ê±´ì§€      0      0 2021-01-01\n"
     ]
    }
   ],
   "source": [
    "# 4-1. ìˆ˜ì¶œ ë°ì´í„° ì›”ë³„ ì§‘ê³„\n",
    "if 'df_export_all' in locals() and df_export_all is not None:\n",
    "    # ìˆ˜ì¶œì•¡ì´ ìˆ«ìí˜•ì´ ì•„ë‹Œ ê²½ìš° ë³€í™˜\n",
    "    numeric_cols = ['ìˆ˜ì¶œì•¡', 'ìˆ˜ì¶œì¤‘ëŸ‰', 'ìˆ˜ì…ì•¡', 'ìˆ˜ì…ì¤‘ëŸ‰']\n",
    "    for col in numeric_cols:\n",
    "        if col in df_export_all.columns and df_export_all[col].dtype == 'object':\n",
    "            df_export_all[col] = df_export_all[col].astype(str).str.replace(',', '').str.replace(' ', '')\n",
    "            df_export_all[col] = pd.to_numeric(df_export_all[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # êµ­ê°€ë³„ ì›”ë³„ ìˆ˜ì¶œì•¡ ì§‘ê³„\n",
    "    export_monthly = df_export_all.groupby(['ì—°ë„', 'ì›”ë³„', 'êµ­ê°€']).agg({\n",
    "        'ìˆ˜ì¶œì•¡': 'sum',\n",
    "        'ìˆ˜ì¶œì¤‘ëŸ‰': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # ì›”ë³„ì„ datetimeìœ¼ë¡œ ë³€í™˜ (ë” ì•ˆì „í•œ ë°©ë²•)\n",
    "    try:\n",
    "        # ì›”ë³„ ë°ì´í„° í˜•íƒœ í™•ì¸\n",
    "        print(f\"ğŸ“… ì›”ë³„ ë°ì´í„° ìƒ˜í”Œ: {export_monthly['ì›”ë³„'].head().tolist()}\")\n",
    "        \n",
    "        # ë‹¤ì–‘í•œ í˜•ì‹ ì²˜ë¦¬\n",
    "        if export_monthly['ì›”ë³„'].dtype == 'object':\n",
    "            # 'YYYY-MM' í˜•íƒœì¸ ê²½ìš°\n",
    "            if export_monthly['ì›”ë³„'].str.contains('-').any():\n",
    "                month_part = export_monthly['ì›”ë³„'].str.split('-').str[1]\n",
    "                export_monthly['ë…„ì›”'] = pd.to_datetime(export_monthly['ì—°ë„'].astype(str) + '-' + \n",
    "                                                      month_part.astype(str) + '-01', errors='coerce')\n",
    "            else:\n",
    "                # ìˆ«ì í˜•íƒœì¸ ê²½ìš° (1, 2, 3, ... 12)\n",
    "                month_part = export_monthly['ì›”ë³„'].astype(str).str.zfill(2)  # 01, 02 í˜•íƒœë¡œ ë³€í™˜\n",
    "                export_monthly['ë…„ì›”'] = pd.to_datetime(export_monthly['ì—°ë„'].astype(str) + '-' + \n",
    "                                                      month_part + '-01', errors='coerce')\n",
    "        else:\n",
    "            # ì´ë¯¸ ìˆ«ìì¸ ê²½ìš°\n",
    "            month_part = export_monthly['ì›”ë³„'].astype(str).str.zfill(2)\n",
    "            export_monthly['ë…„ì›”'] = pd.to_datetime(export_monthly['ì—°ë„'].astype(str) + '-' + \n",
    "                                                  month_part + '-01', errors='coerce')\n",
    "        \n",
    "        # NaT ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "        nat_count = export_monthly['ë…„ì›”'].isna().sum()\n",
    "        if nat_count > 0:\n",
    "            print(f\"âš ï¸ ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ ê±´ìˆ˜: {nat_count}\")\n",
    "            # ì‹¤íŒ¨í•œ ê²½ìš° ë¬¸ìì—´ë¡œ ëŒ€ì²´\n",
    "            failed_mask = export_monthly['ë…„ì›”'].isna()\n",
    "            export_monthly.loc[failed_mask, 'ë…„ì›”'] = (export_monthly.loc[failed_mask, 'ì—°ë„'].astype(str) + '-' + \n",
    "                                                     export_monthly.loc[failed_mask, 'ì›”ë³„'].astype(str))\n",
    "        \n",
    "        print(f\"âœ… ë‚ ì§œ ë³€í™˜ ì™„ë£Œ: {export_monthly['ë…„ì›”'].head().tolist()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {e}\")\n",
    "        # ìµœì¢… ëŒ€ì•ˆ: ë¬¸ìì—´ ì¡°í•©\n",
    "        export_monthly['ë…„ì›”'] = export_monthly['ì—°ë„'].astype(str) + '-' + export_monthly['ì›”ë³„'].astype(str)\n",
    "    \n",
    "    print(f\"âœ… ìˆ˜ì¶œ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: {export_monthly.shape}\")\n",
    "    print(\"ğŸ“Š ì§‘ê³„ëœ ìˆ˜ì¶œ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "    print(export_monthly.head())\n",
    "else:\n",
    "    print(\"âŒ ìˆ˜ì¶œ ë°ì´í„°ê°€ ì—†ì–´ ì§‘ê³„ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    print(\"ğŸ“… ìˆ˜ì¶œ ì›”ë³„ ì§‘ê³„ ì™„ë£Œ\")\n",
    "    print(f\"Shape: {export_monthly.shape}\")\n",
    "    print(export_monthly.head())\n",
    "    \n",
    "    # ìˆ˜ì¶œ ì¦ê°€ìœ¨ ê³„ì‚° (ì „ë…„ë™ì›” ëŒ€ë¹„) - ì•ˆì „í•˜ê²Œ ì²˜ë¦¬\n",
    "    try:\n",
    "        print(\"\\nğŸ“ˆ ìˆ˜ì¶œì¦ê°€ìœ¨ ê³„ì‚° ì‹œì‘...\")\n",
    "        export_monthly = export_monthly.sort_values(['êµ­ê°€', 'ë…„ì›”'])\n",
    "        export_monthly['ì „ë…„ë™ì›”_ìˆ˜ì¶œì•¡'] = export_monthly.groupby('êµ­ê°€')['ìˆ˜ì¶œì•¡'].shift(12)\n",
    "        \n",
    "        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€\n",
    "        mask = export_monthly['ì „ë…„ë™ì›”_ìˆ˜ì¶œì•¡'] > 0\n",
    "        export_monthly['ìˆ˜ì¶œì¦ê°€ìœ¨'] = 0.0  # ê¸°ë³¸ê°’\n",
    "        export_monthly.loc[mask, 'ìˆ˜ì¶œì¦ê°€ìœ¨'] = (\n",
    "            (export_monthly.loc[mask, 'ìˆ˜ì¶œì•¡'] - export_monthly.loc[mask, 'ì „ë…„ë™ì›”_ìˆ˜ì¶œì•¡']) / \n",
    "            export_monthly.loc[mask, 'ì „ë…„ë™ì›”_ìˆ˜ì¶œì•¡'] * 100\n",
    "        ).round(2)\n",
    "        \n",
    "        print(\"âœ… ìˆ˜ì¶œì¦ê°€ìœ¨ ê³„ì‚° ì™„ë£Œ\")\n",
    "        valid_growth = export_monthly[export_monthly['ìˆ˜ì¶œì¦ê°€ìœ¨'] != 0].head(10)\n",
    "        if not valid_growth.empty:\n",
    "            print(\"ğŸ“Š ìˆ˜ì¶œì¦ê°€ìœ¨ ìƒ˜í”Œ:\")\n",
    "            print(valid_growth[['êµ­ê°€', 'ë…„ì›”', 'ìˆ˜ì¶œì•¡', 'ìˆ˜ì¶œì¦ê°€ìœ¨']])\n",
    "        else:\n",
    "            print(\"âš ï¸ ê³„ì‚°ëœ ìˆ˜ì¶œì¦ê°€ìœ¨ì´ ì—†ìŠµë‹ˆë‹¤ (ë°ì´í„° ê¸°ê°„ ë¶€ì¡± ê°€ëŠ¥)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ìˆ˜ì¶œì¦ê°€ìœ¨ ê³„ì‚° ì˜¤ë¥˜: {e}\")\n",
    "        export_monthly['ìˆ˜ì¶œì¦ê°€ìœ¨'] = 0.0  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ êµ­ê°€ëª… í‘œì¤€í™” ì‘ì—…\n",
      "âœ… ë¡œë”©ëœ ë°ì´í„°ì…‹: 3ê°œ\n",
      "export ë°ì´í„° êµ­ê°€ ìˆ˜: 252\n",
      "claims ë°ì´í„° êµ­ê°€ ìˆ˜: 196\n",
      "risk ë°ì´í„° êµ­ê°€ ìˆ˜: 165\n",
      "\n",
      "ğŸŒ ê³µí†µ êµ­ê°€ ìˆ˜: 129\n",
      "ê³µí†µ êµ­ê°€ (ìƒìœ„ 10ê°œ): ['íŒŒë‚˜ë§ˆ', 'ë©•ì‹œì½”', 'ë¯¸ì–€ë§ˆ', 'ëŒ€ë§Œ', 'ì‹±ê°€í¬ë¥´', 'ì—ìŠ¤í† ë‹ˆì•„', 'ì´ìŠ¤ë¼ì—˜', 'ë°”í•˜ë§ˆ', 'ì½”ìŠ¤íƒ€ë¦¬ì¹´', 'íŒŒí‚¤ìŠ¤íƒ„']\n",
      "âœ… export ë°ì´í„° í•„í„°ë§: (4642, 6)\n",
      "âœ… claims ë°ì´í„° í•„í„°ë§: (887, 8)\n",
      "âœ… risk ë°ì´í„° í•„í„°ë§: (22333, 4)\n"
     ]
    }
   ],
   "source": [
    "# 4-2. êµ­ê°€ëª… í‘œì¤€í™” (3ê°œ ë°ì´í„°ì…‹ ê°„ ë§¤ì¹­)\n",
    "print(\"ğŸ”§ êµ­ê°€ëª… í‘œì¤€í™” ì‘ì—…\")\n",
    "\n",
    "# ë°ì´í„°ê°€ ë¡œë”©ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "datasets_loaded = []\n",
    "if 'export_monthly' in locals() and export_monthly is not None:\n",
    "    datasets_loaded.append(('export', export_monthly, 'êµ­ê°€'))\n",
    "if 'df_claims_2024' in locals() and df_claims_2024 is not None:\n",
    "    datasets_loaded.append(('claims', df_claims_2024, 'êµ­ê°€ëª…'))\n",
    "if 'df_risk_2025' in locals() and df_risk_2025 is not None:\n",
    "    datasets_loaded.append(('risk', df_risk_2025, 'êµ­ê°€ëª…'))\n",
    "\n",
    "print(f\"âœ… ë¡œë”©ëœ ë°ì´í„°ì…‹: {len(datasets_loaded)}ê°œ\")\n",
    "\n",
    "if len(datasets_loaded) >= 2:\n",
    "    # ê° ë°ì´í„°ì…‹ì˜ ê³ ìœ  êµ­ê°€ëª… í™•ì¸\n",
    "    country_sets = {}\n",
    "    for name, df, col in datasets_loaded:\n",
    "        countries = set(df[col].unique())\n",
    "        country_sets[name] = countries\n",
    "        print(f\"{name} ë°ì´í„° êµ­ê°€ ìˆ˜: {len(countries)}\")\n",
    "    \n",
    "    # ê³µí†µ êµ­ê°€ ì°¾ê¸° (ìµœì†Œ 2ê°œ ì´ìƒì˜ ë°ì´í„°ì…‹ì—ì„œ ê³µí†µì¸ êµ­ê°€)\n",
    "    if len(datasets_loaded) >= 3:\n",
    "        common_countries = set.intersection(*country_sets.values())\n",
    "    else:\n",
    "        # 2ê°œ ë°ì´í„°ì…‹ë§Œ ìˆëŠ” ê²½ìš°\n",
    "        common_countries = set.intersection(*list(country_sets.values()))\n",
    "    \n",
    "    print(f\"\\nğŸŒ ê³µí†µ êµ­ê°€ ìˆ˜: {len(common_countries)}\")\n",
    "    if common_countries:\n",
    "        print(f\"ê³µí†µ êµ­ê°€ (ìƒìœ„ 10ê°œ): {list(common_countries)[:10]}\")\n",
    "        \n",
    "        # ë¶„ì„ìš© ë°ì´í„°ì…‹ í•„í„°ë§ (ê³µí†µ êµ­ê°€ë§Œ)\n",
    "        filtered_datasets = {}\n",
    "        for name, df, col in datasets_loaded:\n",
    "            filtered = df[df[col].isin(common_countries)].copy()\n",
    "            filtered_datasets[name] = filtered\n",
    "            print(f\"âœ… {name} ë°ì´í„° í•„í„°ë§: {filtered.shape}\")\n",
    "    else:\n",
    "        print(\"âŒ ê³µí†µ êµ­ê°€ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        # ê° ë°ì´í„°ì…‹ì„ ê·¸ëŒ€ë¡œ ì €ì¥\n",
    "        filtered_datasets = {name: df for name, df, col in datasets_loaded}\n",
    "else:\n",
    "    print(\"âŒ ë¡œë”©ëœ ë°ì´í„°ì…‹ì´ ë¶€ì¡±í•©ë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ë¶„ì„ìš© ë°ì´í„°ì…‹ ì €ì¥\n",
      "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼:\n",
      "- export_data_processed.csv: ìˆ˜ì¶œì… ì‹¤ì  (2021-2023)\n",
      "- claims_data_processed.csv: ë³´ìƒí˜„í™© (2024)\n",
      "- risk_data_processed.csv: AI ìœ„í—˜ì§€ìˆ˜ (2025)\n",
      "- common_countries.csv: ê³µí†µ êµ­ê°€ ë¦¬ìŠ¤íŠ¸\n",
      "\n",
      "ğŸ“Š ìµœì¢… ë°ì´í„° ìš”ì•½:\n",
      "- ë¶„ì„ ëŒ€ìƒ êµ­ê°€: 129ê°œêµ­\n",
      "- ìˆ˜ì¶œ ë°ì´í„° ê¸°ê°„: 2021-2023 (36ê°œì›”)\n",
      "- ë³´ìƒ ë°ì´í„° ê¸°ê°„: 2021-2024\n",
      "- AI ìœ„í—˜ì§€ìˆ˜: 2025ë…„ 4ì›” ê¸°ì¤€\n",
      "\n",
      "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: 02_lag_effect_analysis.ipynb ì‹¤í–‰!\n"
     ]
    }
   ],
   "source": [
    "# 4-3. ë¶„ì„ìš© ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥\n",
    "print(\"ğŸ’¾ ë¶„ì„ìš© ë°ì´í„°ì…‹ ì €ì¥\")\n",
    "\n",
    "# Output í´ë” ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš°)\n",
    "OUTPUT_PATH = Path('../output')\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "if 'filtered_datasets' in locals() and filtered_datasets:\n",
    "    saved_files = []\n",
    "    \n",
    "    # ê° ë°ì´í„°ì…‹ì„ ì €ì¥\n",
    "    if 'export' in filtered_datasets:\n",
    "        filtered_datasets['export'].to_csv(OUTPUT_PATH / 'export_data_processed.csv', index=False, encoding='cp949')\n",
    "        saved_files.append(\"- export_data_processed.csv: ìˆ˜ì¶œì… ì‹¤ì  (2021-2023)\")\n",
    "    \n",
    "    if 'claims' in filtered_datasets:\n",
    "        filtered_datasets['claims'].to_csv(OUTPUT_PATH / 'claims_data_processed.csv', index=False, encoding='cp949')\n",
    "        saved_files.append(\"- claims_data_processed.csv: ë³´ìƒí˜„í™© (2024)\")\n",
    "    \n",
    "    if 'risk' in filtered_datasets:\n",
    "        filtered_datasets['risk'].to_csv(OUTPUT_PATH / 'risk_data_processed.csv', index=False, encoding='cp949')\n",
    "        saved_files.append(\"- risk_data_processed.csv: AI ìœ„í—˜ì§€ìˆ˜ (2025)\")\n",
    "    \n",
    "    # ê³µí†µ êµ­ê°€ ë¦¬ìŠ¤íŠ¸ ì €ì¥ (ìˆëŠ” ê²½ìš°)\n",
    "    if 'common_countries' in locals() and common_countries:\n",
    "        pd.DataFrame(list(common_countries), columns=['êµ­ê°€ëª…']).to_csv(\n",
    "            OUTPUT_PATH / 'common_countries.csv', index=False, encoding='cp949')\n",
    "        saved_files.append(\"- common_countries.csv: ê³µí†µ êµ­ê°€ ë¦¬ìŠ¤íŠ¸\")\n",
    "    \n",
    "    print(\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼:\")\n",
    "    for file in saved_files:\n",
    "        print(file)\n",
    "    \n",
    "    # ìµœì¢… ë°ì´í„° ìš”ì•½\n",
    "    print(f\"\\nğŸ“Š ìµœì¢… ë°ì´í„° ìš”ì•½:\")\n",
    "    if 'common_countries' in locals() and common_countries:\n",
    "        print(f\"- ë¶„ì„ ëŒ€ìƒ êµ­ê°€: {len(common_countries)}ê°œêµ­\")\n",
    "    \n",
    "    if 'export' in filtered_datasets:\n",
    "        export_data = filtered_datasets['export']\n",
    "        if 'ë…„ì›”' in export_data.columns:\n",
    "            print(f\"- ìˆ˜ì¶œ ë°ì´í„° ê¸°ê°„: 2021-2023 ({export_data['ë…„ì›”'].nunique()}ê°œì›”)\")\n",
    "        else:\n",
    "            print(f\"- ìˆ˜ì¶œ ë°ì´í„°: {export_data.shape}\")\n",
    "    \n",
    "    if 'claims' in filtered_datasets:\n",
    "        claims_data = filtered_datasets['claims']\n",
    "        if 'ì—°ë„' in claims_data.columns:\n",
    "            print(f\"- ë³´ìƒ ë°ì´í„° ê¸°ê°„: {claims_data['ì—°ë„'].min()}-{claims_data['ì—°ë„'].max()}\")\n",
    "        else:\n",
    "            print(f\"- ë³´ìƒ ë°ì´í„°: {claims_data.shape}\")\n",
    "    \n",
    "    if 'risk' in filtered_datasets:\n",
    "        print(f\"- AI ìœ„í—˜ì§€ìˆ˜: 2025ë…„ 4ì›” ê¸°ì¤€\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "print(\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: 02_lag_effect_analysis.ipynb ì‹¤í–‰!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
