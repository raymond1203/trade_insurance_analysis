{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 04 í†µí•© ì˜ˆì¸¡ ëª¨ë¸ë§\n",
    "\n",
    "## ëª©í‘œ\n",
    "- Lag Effect + AI ìœ„í—˜ì§€ìˆ˜ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì¶•\n",
    "- ì•™ìƒë¸” ê¸°ë²•ì„ í™œìš©í•œ ìµœì  ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ\n",
    "- ì‹œë‚˜ë¦¬ì˜¤ë³„ ìœ„í—˜ ì˜ˆì¸¡ (ë‚™ê´€ì /ë¹„ê´€ì /í˜„ì‹¤ì )\n",
    "- 2026ë…„ ë¬´ì—­ë³´í—˜ ìœ„í—˜ ì „ë§\n",
    "\n",
    "## í•µì‹¬ ì•„ì´ë””ì–´\n",
    "**\"ê³¼ê±° íŒ¨í„´ + AI ì˜ˆì¸¡ = ìµœê°• ì¡°í•©\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# ì»¤ìŠ¤í…€ í•¨ìˆ˜ import\n",
    "from prediction_utils import (create_lag_features, create_ai_features, \n",
    "                             create_interaction_features, build_ensemble_model, \n",
    "                             predict_scenarios)\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"ğŸš€ í†µí•© ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶• ì‹œì‘!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”©\n",
    "try:\n",
    "    export_data = pd.read_csv('../output/export_data_processed.csv', encoding='cp949')\n",
    "    claims_data = pd.read_csv('../output/claims_data_processed.csv', encoding='cp949')\n",
    "    risk_data = pd.read_csv('../output/risk_data_processed.csv', encoding='cp949')\n",
    "    \n",
    "    # ë…„ì›” ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜\n",
    "    export_data['ë…„ì›”'] = pd.to_datetime(export_data['ë…„ì›”'])\n",
    "    \n",
    "    print(\"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ\")\n",
    "    print(f\"ìˆ˜ì¶œ ë°ì´í„°: {export_data.shape}\")\n",
    "    print(f\"ë³´ìƒ ë°ì´í„°: {claims_data.shape}\")\n",
    "    print(f\"ìœ„í—˜ì§€ìˆ˜ ë°ì´í„°: {risk_data.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ë¨¼ì € 01_data_preparation.ipynbë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-1. ì‹œì°¨ ê¸°ë°˜ í”¼ì²˜ ìƒì„±\n",
    "print(\"ğŸ”„ ì‹œì°¨ ê¸°ë°˜ í”¼ì²˜ ìƒì„±\")\n",
    "lag_features = create_lag_features(export_data)\n",
    "\n",
    "if not lag_features.empty:\n",
    "    print(f\"âœ… ì‹œì°¨ í”¼ì²˜ ìƒì„± ì™„ë£Œ: {lag_features.shape}\")\n",
    "    print(\"\\nğŸ“Š ì‹œì°¨ í”¼ì²˜ ìƒ˜í”Œ:\")\n",
    "    print(lag_features.head())\n",
    "    \n",
    "    # ì£¼ìš” í†µê³„\n",
    "    print(f\"\\nğŸ“ˆ ì£¼ìš” í†µê³„:\")\n",
    "    print(f\"- í‰ê·  ì´ìˆ˜ì¶œì•¡: {lag_features['ì´ìˆ˜ì¶œì•¡'].mean():.0f}\")\n",
    "    print(f\"- í‰ê·  ìˆ˜ì¶œë³€ë™ì„±: {lag_features['ìˆ˜ì¶œë³€ë™ì„±'].mean():.0f}\")\n",
    "    print(f\"- í‰ê·  ê³„ì ˆì„± ë³€ë™ê³„ìˆ˜: {lag_features['ê³„ì ˆì„±_ë³€ë™ê³„ìˆ˜'].mean():.4f}\")\n",
    "else:\n",
    "    print(\"âŒ ì‹œì°¨ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨\")\n",
    "\n",
    "# 1-2. AI ìœ„í—˜ì§€ìˆ˜ ê¸°ë°˜ í”¼ì²˜ ìƒì„±\n",
    "print(\"\\nğŸ¤– AI ìœ„í—˜ì§€ìˆ˜ ê¸°ë°˜ í”¼ì²˜ ìƒì„±\")\n",
    "ai_features = create_ai_features(risk_data)\n",
    "\n",
    "if not ai_features.empty:\n",
    "    print(f\"âœ… AI í”¼ì²˜ ìƒì„± ì™„ë£Œ: {ai_features.shape}\")\n",
    "    print(\"\\nğŸ“Š AI í”¼ì²˜ ìƒ˜í”Œ:\")\n",
    "    print(ai_features.head())\n",
    "    \n",
    "    # ìœ„í—˜ë“±ê¸‰ë³„ ë¶„í¬\n",
    "    print(f\"\\nğŸ¯ ìœ„í—˜ë“±ê¸‰ë³„ ë¶„í¬:\")\n",
    "    print(ai_features['ìœ„í—˜ë“±ê¸‰'].value_counts())\n",
    "else:\n",
    "    print(\"âŒ AI í”¼ì²˜ ìƒì„± ì‹¤íŒ¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-3. ìƒí˜¸ì‘ìš© í”¼ì²˜ ìƒì„± ë° íƒ€ê²Ÿ ë³€ìˆ˜ ì¤€ë¹„\n",
    "print(\"âš¡ ìƒí˜¸ì‘ìš© í”¼ì²˜ ìƒì„±\")\n",
    "\n",
    "if not lag_features.empty and not ai_features.empty:\n",
    "    # ìƒí˜¸ì‘ìš© í”¼ì²˜ ìƒì„±\n",
    "    integrated_features = create_interaction_features(lag_features, ai_features)\n",
    "    \n",
    "    if not integrated_features.empty:\n",
    "        print(f\"âœ… í†µí•© í”¼ì²˜ ìƒì„± ì™„ë£Œ: {integrated_features.shape}\")\n",
    "        print(f\"ğŸ“Š ì´ í”¼ì²˜ ìˆ˜: {len(integrated_features.columns)}\")\n",
    "        \n",
    "        # ë³´ìƒ ë°ì´í„°ì™€ ë³‘í•©í•˜ì—¬ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±\n",
    "        claims_agg = claims_data.groupby('êµ­ê°€ëª…').agg({\n",
    "            'ë³´ìƒê¸ˆ': 'sum',\n",
    "            'íšŒìˆ˜ê¸ˆ': 'sum', \n",
    "            'ë³´ìƒë¥ ': 'mean'\n",
    "        }).reset_index()\n",
    "        claims_agg.rename(columns={'êµ­ê°€ëª…': 'êµ­ê°€'}, inplace=True)\n",
    "        \n",
    "        # ìµœì¢… ëª¨ë¸ë§ ë°ì´í„°ì…‹\n",
    "        model_data = pd.merge(integrated_features, claims_agg, on='êµ­ê°€', how='inner')\n",
    "        \n",
    "        print(f\"\\nğŸ¯ ìµœì¢… ëª¨ë¸ë§ ë°ì´í„°ì…‹: {model_data.shape}\")\n",
    "        print(f\"- ë¶„ì„ ëŒ€ìƒ êµ­ê°€: {len(model_data)}ê°œêµ­\")\n",
    "        \n",
    "        # íƒ€ê²Ÿ ë³€ìˆ˜ í†µê³„\n",
    "        print(f\"\\nğŸ’° íƒ€ê²Ÿ ë³€ìˆ˜ í†µê³„:\")\n",
    "        print(f\"- í‰ê·  ë³´ìƒê¸ˆ: {model_data['ë³´ìƒê¸ˆ'].mean():.0f}\")\n",
    "        print(f\"- ìµœëŒ€ ë³´ìƒê¸ˆ: {model_data['ë³´ìƒê¸ˆ'].max():.0f}\")\n",
    "        print(f\"- í‰ê·  ë³´ìƒë¥ : {model_data['ë³´ìƒë¥ '].mean():.4f}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ìƒí˜¸ì‘ìš© í”¼ì²˜ ìƒì„± ì‹¤íŒ¨\")\n",
    "else:\n",
    "    print(\"âŒ ê¸°ë³¸ í”¼ì²˜ê°€ ìƒì„±ë˜ì§€ ì•Šì•„ ìƒí˜¸ì‘ìš© í”¼ì²˜ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¶•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-1. ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ\n",
    "print(\"ğŸš€ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¶• ì‹œì‘\")\n",
    "\n",
    "if 'model_data' in locals() and not model_data.empty:\n",
    "    # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "    feature_cols = [col for col in model_data.columns \n",
    "                   if col not in ['êµ­ê°€', 'ë³´ìƒê¸ˆ', 'íšŒìˆ˜ê¸ˆ', 'ë³´ìƒë¥ ']]\n",
    "    \n",
    "    X = model_data[feature_cols]\n",
    "    y = model_data['ë³´ìƒê¸ˆ']  # ë³´ìƒê¸ˆì„ íƒ€ê²Ÿìœ¼ë¡œ ì„¤ì •\n",
    "    \n",
    "    print(f\"ğŸ“Š ëª¨ë¸ í•™ìŠµ ë°ì´í„°:\")\n",
    "    print(f\"- í”¼ì²˜ ìˆ˜: {len(feature_cols)}\")\n",
    "    print(f\"- ìƒ˜í”Œ ìˆ˜: {len(X)}\")\n",
    "    print(f\"- íƒ€ê²Ÿ: ë³´ìƒê¸ˆ\")\n",
    "    \n",
    "    # ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¶•\n",
    "    ensemble_model, performance = build_ensemble_model(X, y)\n",
    "    \n",
    "    if ensemble_model is not None:\n",
    "        print(f\"\\nâœ… ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "        print(f\"\\nğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥:\")\n",
    "        print(f\"- MAE (í‰ê· ì ˆëŒ€ì˜¤ì°¨): {performance['mae']:.2f}\")\n",
    "        print(f\"- MSE (í‰ê· ì œê³±ì˜¤ì°¨): {performance['mse']:.2e}\")\n",
    "        print(f\"- RÂ² ì ìˆ˜: {performance['r2']:.4f}\")\n",
    "        print(f\"- í›ˆë ¨ ë°ì´í„° í¬ê¸°: {performance['train_size']}\")\n",
    "        print(f\"- í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {performance['test_size']}\")\n",
    "        \n",
    "        # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„\n",
    "        feature_importance = feature_importance_analysis(ensemble_model, feature_cols)\n",
    "        \n",
    "        if not feature_importance.empty:\n",
    "            print(f\"\\nğŸ” ìƒìœ„ 10ê°œ ì¤‘ìš” í”¼ì²˜:\")\n",
    "            top_features = feature_importance.head(10)\n",
    "            for idx, row in top_features.iterrows():\n",
    "                print(f\"- {row['feature']}: {row['importance']:.4f}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¶• ì‹¤íŒ¨\")\n",
    "else:\n",
    "    print(\"âŒ ëª¨ë¸ë§ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-1. ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜ ë° ì˜ˆì¸¡\n",
    "print(\"ğŸ”® ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì˜ˆì¸¡ ìˆ˜í–‰\")\n",
    "\n",
    "if 'ensemble_model' in locals() and ensemble_model is not None:\n",
    "    # ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜\n",
    "    scenarios = {\n",
    "        'optimistic': 'ë‚™ê´€ì  ì‹œë‚˜ë¦¬ì˜¤: ìˆ˜ì¶œ 10% ì¦ê°€, ìœ„í—˜ì§€ìˆ˜ 10% ê°ì†Œ',\n",
    "        'realistic': 'í˜„ì‹¤ì  ì‹œë‚˜ë¦¬ì˜¤: í˜„ì¬ íŠ¸ë Œë“œ ìœ ì§€',\n",
    "        'pessimistic': 'ë¹„ê´€ì  ì‹œë‚˜ë¦¬ì˜¤: ìˆ˜ì¶œ 20% ê°ì†Œ, ìœ„í—˜ì§€ìˆ˜ 20% ì¦ê°€'\n",
    "    }\n",
    "    \n",
    "    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜ˆì¸¡\n",
    "    scenario_results = predict_scenarios(ensemble_model, model_data[feature_cols], scenarios)\n",
    "    \n",
    "    if scenario_results:\n",
    "        print(f\"\\nğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜ˆì¸¡ ê²°ê³¼:\")\n",
    "        \n",
    "        for scenario, result in scenario_results.items():\n",
    "            print(f\"\\nğŸ¯ {scenario.upper()}:\")\n",
    "            print(f\"   {result['description']}\")\n",
    "            print(f\"   - í‰ê·  ì˜ˆìƒ ë³´ìƒê¸ˆ: {result['mean_prediction']:,.0f}\")\n",
    "            print(f\"   - ì˜ˆì¸¡ ë²”ìœ„: {result['min_prediction']:,.0f} ~ {result['max_prediction']:,.0f}\")\n",
    "            print(f\"   - í‘œì¤€í¸ì°¨: {result['std_prediction']:,.0f}\")\n",
    "        \n",
    "        # ì‹œë‚˜ë¦¬ì˜¤ ê°„ ë¹„êµ\n",
    "        base_prediction = scenario_results['realistic']['mean_prediction']\n",
    "        optimistic_change = (scenario_results['optimistic']['mean_prediction'] - base_prediction) / base_prediction * 100\n",
    "        pessimistic_change = (scenario_results['pessimistic']['mean_prediction'] - base_prediction) / base_prediction * 100\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ í˜„ì‹¤ì  ì‹œë‚˜ë¦¬ì˜¤ ëŒ€ë¹„ ë³€í™”ìœ¨:\")\n",
    "        print(f\"- ë‚™ê´€ì  ì‹œë‚˜ë¦¬ì˜¤: {optimistic_change:+.1f}%\")\n",
    "        print(f\"- ë¹„ê´€ì  ì‹œë‚˜ë¦¬ì˜¤: {pessimistic_change:+.1f}%\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ ì‹¤íŒ¨\")\n",
    "else:\n",
    "    print(\"âŒ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ì–´ ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. ëª¨ë¸ ê²°ê³¼ ì‹œê°í™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-1. í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "if 'feature_importance' in locals() and not feature_importance.empty:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # ìƒìœ„ 15ê°œ í”¼ì²˜\n",
    "    top_15_features = feature_importance.head(15)\n",
    "    \n",
    "    plt.barh(range(len(top_15_features)), top_15_features['importance'], \n",
    "             color='skyblue', alpha=0.8)\n",
    "    plt.yticks(range(len(top_15_features)), top_15_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('ğŸ” ìƒìœ„ 15ê°œ í”¼ì²˜ ì¤‘ìš”ë„', fontsize=16, pad=20)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # ì¤‘ìš”ë„ ê°’ í‘œì‹œ\n",
    "    for i, v in enumerate(top_15_features['importance']):\n",
    "        plt.text(v + 0.001, i, f'{v:.3f}', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ“Š í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ ê²°ê³¼:\")\n",
    "    print(\"- ìˆ˜ì¶œ ê´€ë ¨ í”¼ì²˜ì™€ ìœ„í—˜ì§€ìˆ˜ í”¼ì²˜ê°€ ì–´ë–»ê²Œ ê¸°ì—¬í•˜ëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"- ì‹œì°¨ í”¼ì²˜ë“¤ì˜ ìƒëŒ€ì  ì¤‘ìš”ë„ ë¹„êµ ê°€ëŠ¥\")\n",
    "\n",
    "# 4-2. ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "if 'scenario_results' in locals() and scenario_results:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    scenarios_list = list(scenario_results.keys())\n",
    "    means = [scenario_results[s]['mean_prediction'] for s in scenarios_list]\n",
    "    stds = [scenario_results[s]['std_prediction'] for s in scenarios_list]\n",
    "    \n",
    "    colors = ['green', 'blue', 'red']\n",
    "    bars = plt.bar(scenarios_list, means, yerr=stds, capsize=5, \n",
    "                   color=colors, alpha=0.7)\n",
    "    \n",
    "    plt.title('ğŸ”® ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜ˆìƒ ë³´ìƒê¸ˆ', fontsize=16, pad=20)\n",
    "    plt.ylabel('ì˜ˆìƒ ë³´ìƒê¸ˆ')\n",
    "    plt.xlabel('ì‹œë‚˜ë¦¬ì˜¤')\n",
    "    \n",
    "    # ê°’ í‘œì‹œ\n",
    "    for bar, mean in zip(bars, means):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(stds)*0.1,\n",
    "                f'{mean:,.0f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ“ˆ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ í•´ì„:\")\n",
    "    print(\"- ë‚™ê´€ì  ì‹œë‚˜ë¦¬ì˜¤: ë¦¬ìŠ¤í¬ ê°ì†Œ íš¨ê³¼\")\n",
    "    print(\"- ë¹„ê´€ì  ì‹œë‚˜ë¦¬ì˜¤: ë¦¬ìŠ¤í¬ ì¦ê°€ ì˜í–¥\")\n",
    "    print(\"- ì˜¤ì°¨ë§‰ëŒ€: ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„± í‘œì‹œ\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. ê²°ê³¼ ì €ì¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-1. ëª¨ë¸ë§ ê²°ê³¼ ì €ì¥\n",
    "print(\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...\")\n",
    "\n",
    "try:\n",
    "    # í†µí•© í”¼ì²˜ ë°ì´í„° ì €ì¥\n",
    "    if 'model_data' in locals():\n",
    "        model_data.to_csv('../output/integrated_model_data.csv', index=False, encoding='cp949')\n",
    "        print(\"âœ… í†µí•© ëª¨ë¸ ë°ì´í„° ì €ì¥ ì™„ë£Œ\")\n",
    "    \n",
    "    # í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥\n",
    "    if 'feature_importance' in locals() and not feature_importance.empty:\n",
    "        feature_importance.to_csv('../output/feature_importance.csv', index=False, encoding='cp949')\n",
    "        print(\"âœ… í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥ ì™„ë£Œ\")\n",
    "    \n",
    "    # ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
    "    if 'scenario_results' in locals() and scenario_results:\n",
    "        scenario_df = pd.DataFrame([\n",
    "            {\n",
    "                'scenario': scenario,\n",
    "                'description': result['description'],\n",
    "                'mean_prediction': result['mean_prediction'],\n",
    "                'std_prediction': result['std_prediction'],\n",
    "                'min_prediction': result['min_prediction'],\n",
    "                'max_prediction': result['max_prediction']\n",
    "            }\n",
    "            for scenario, result in scenario_results.items()\n",
    "        ])\n",
    "        scenario_df.to_csv('../output/scenario_predictions.csv', index=False, encoding='cp949')\n",
    "        print(\"âœ… ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ\")\n",
    "    \n",
    "    # ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ì €ì¥\n",
    "    if 'performance' in locals():\n",
    "        performance_df = pd.DataFrame([performance])\n",
    "        performance_df.to_csv('../output/model_performance.csv', index=False, encoding='cp949')\n",
    "        print(\"âœ… ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ì €ì¥ ì™„ë£Œ\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ í†µí•© ëª¨ë¸ë§ ë¶„ì„ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤:\")\n",
    "    print(f\"- integrated_model_data.csv: í†µí•© ëª¨ë¸ë§ ë°ì´í„°\")\n",
    "    print(f\"- feature_importance.csv: í”¼ì²˜ ì¤‘ìš”ë„\")\n",
    "    print(f\"- scenario_predictions.csv: ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡\")\n",
    "    print(f\"- model_performance.csv: ëª¨ë¸ ì„±ëŠ¥\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ”¥ ë‹¤ìŒ ë‹¨ê³„: 05_result_visualization.ipynbë¡œ ìµœì¢… ê²°ê³¼ ì‹œê°í™”!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
